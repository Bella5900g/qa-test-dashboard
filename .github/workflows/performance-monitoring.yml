# QA Test Automation Dashboard - Performance Monitoring
# Desenvolvido por Isabella Barbosa - Engenheira de QA SÃªnior

name: ðŸ“Š Performance Monitoring

on:
  schedule:
    # Executar monitoramento de performance diariamente Ã s 3h UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Tipo de teste de performance'
        required: true
        default: 'load'
        type: choice
        options:
        - load
        - stress
        - spike
        - volume

jobs:
  # =============================================================================
  # Job: Testes de Performance Automatizados
  # =============================================================================
  performance-tests:
    name: âš¡ Testes de Performance
    runs-on: ubuntu-latest

    steps:
      - name: ðŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ðŸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ðŸ“¦ Instalar dependÃªncias
        run: |
          python -m pip install --upgrade pip
          pip install -r backend/requirements.txt
          pip install requests psutil

      - name: ðŸš€ Iniciar backend
        run: |
          cd backend
          python app.py &
          sleep 15

      - name: âš¡ Executar testes de performance
        run: |
          cd automation/performance
          python run_performance_tests.py

      - name: ðŸ“Š Analisar resultados
        run: |
          cd automation/performance/results
          
          # Extrair mÃ©tricas dos resultados
          if [ -f "performance_results.jtl" ]; then
            echo "## ðŸ“Š MÃ©tricas de Performance" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Contar total de requests
            total_requests=$(tail -n +2 performance_results.jtl | wc -l)
            echo "**Total de Requests:** $total_requests" >> $GITHUB_STEP_SUMMARY
            
            # Calcular taxa de sucesso
            successful_requests=$(tail -n +2 performance_results.jtl | awk -F',' '$8=="true"' | wc -l)
            success_rate=$((successful_requests * 100 / total_requests))
            echo "**Taxa de Sucesso:** $success_rate%" >> $GITHUB_STEP_SUMMARY
            
            # Calcular tempo mÃ©dio de resposta
            avg_response_time=$(tail -n +2 performance_results.jtl | awk -F',' '{sum+=$2; count++} END {print sum/count}')
            echo "**Tempo MÃ©dio de Resposta:** ${avg_response_time}ms" >> $GITHUB_STEP_SUMMARY
            
            # Calcular throughput
            throughput=$(echo "scale=2; $total_requests / 300" | bc)
            echo "**Throughput:** ${throughput} req/s" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ðŸ“„ Upload relatÃ³rios de performance
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-reports-${{ github.run_number }}
          path: |
            automation/performance/results/
          retention-days: 30

  # =============================================================================
  # Job: Monitoramento de MÃ©tricas do Sistema
  # =============================================================================
  system-monitoring:
    name: ðŸ–¥ï¸ Monitoramento do Sistema
    runs-on: ubuntu-latest

    steps:
      - name: ðŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ðŸ Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: ðŸ“¦ Instalar dependÃªncias
        run: |
          python -m pip install --upgrade pip
          pip install psutil requests

      - name: ðŸš€ Iniciar backend
        run: |
          cd backend
          python app.py &
          sleep 10

      - name: ðŸ“Š Coletar mÃ©tricas do sistema
        run: |
          python -c "
          import psutil
          import requests
          import json
          import time
          from datetime import datetime
          
          # Coletar mÃ©tricas por 5 minutos
          metrics = []
          for i in range(30):  # 30 amostras de 10 segundos cada
              # MÃ©tricas do sistema
              cpu_percent = psutil.cpu_percent(interval=1)
              memory = psutil.virtual_memory()
              disk = psutil.disk_usage('/')
              
              # MÃ©tricas da aplicaÃ§Ã£o
              try:
                  response = requests.get('http://localhost:5000/api/sistema', timeout=5)
                  app_metrics = response.json()
              except:
                  app_metrics = {'cpu': 0, 'memoria': 0, 'disco': 0, 'rede': 0}
              
              metric = {
                  'timestamp': datetime.now().isoformat(),
                  'system_cpu': cpu_percent,
                  'system_memory': memory.percent,
                  'system_disk': (disk.used / disk.total) * 100,
                  'app_cpu': app_metrics.get('cpu', 0),
                  'app_memory': app_metrics.get('memoria', 0),
                  'app_disk': app_metrics.get('disco', 0),
                  'app_network': app_metrics.get('rede', 0)
              }
              
              metrics.append(metric)
              time.sleep(10)
          
          # Salvar mÃ©tricas
          with open('system_metrics.json', 'w') as f:
              json.dump(metrics, f, indent=2)
          
          print(f'âœ… Coletadas {len(metrics)} amostras de mÃ©tricas')
          "

      - name: ðŸ“Š Analisar mÃ©tricas coletadas
        run: |
          python -c "
          import json
          import statistics
          
          with open('system_metrics.json', 'r') as f:
              metrics = json.load(f)
          
          if metrics:
              # Calcular estatÃ­sticas
              system_cpu = [m['system_cpu'] for m in metrics]
              system_memory = [m['system_memory'] for m in metrics]
              app_cpu = [m['app_cpu'] for m in metrics]
              app_memory = [m['app_memory'] for m in metrics]
              
              print('## ðŸ–¥ï¸ MÃ©tricas do Sistema')
              print('')
              print(f'**CPU do Sistema:**')
              print(f'- MÃ©dia: {statistics.mean(system_cpu):.2f}%')
              print(f'- MÃ¡ximo: {max(system_cpu):.2f}%')
              print(f'- MÃ­nimo: {min(system_cpu):.2f}%')
              print('')
              print(f'**MemÃ³ria do Sistema:**')
              print(f'- MÃ©dia: {statistics.mean(system_memory):.2f}%')
              print(f'- MÃ¡ximo: {max(system_memory):.2f}%')
              print(f'- MÃ­nimo: {min(system_memory):.2f}%')
              print('')
              print(f'**CPU da AplicaÃ§Ã£o:**')
              print(f'- MÃ©dia: {statistics.mean(app_cpu):.2f}%')
              print(f'- MÃ¡ximo: {max(app_cpu):.2f}%')
              print(f'- MÃ­nimo: {min(app_cpu):.2f}%')
              print('')
              print(f'**MemÃ³ria da AplicaÃ§Ã£o:**')
              print(f'- MÃ©dia: {statistics.mean(app_memory):.2f}%')
              print(f'- MÃ¡ximo: {max(app_memory):.2f}%')
              print(f'- MÃ­nimo: {min(app_memory):.2f}%')
          "

      - name: ðŸ“„ Upload mÃ©tricas do sistema
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: system-metrics-${{ github.run_number }}
          path: system_metrics.json
          retention-days: 30

  # =============================================================================
  # Job: AnÃ¡lise de TendÃªncias
  # =============================================================================
  trend-analysis:
    name: ðŸ“ˆ AnÃ¡lise de TendÃªncias
    runs-on: ubuntu-latest
    needs: [performance-tests, system-monitoring]

    steps:
      - name: ðŸ“¥ Checkout cÃ³digo
        uses: actions/checkout@v4

      - name: ðŸ“Š Download artefatos anteriores
        uses: actions/download-artifact@v4
        with:
          pattern: performance-reports-*
          path: ./previous-reports
          merge-multiple: true

      - name: ðŸ“ˆ Analisar tendÃªncias
        run: |
          echo "## ðŸ“ˆ AnÃ¡lise de TendÃªncias" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š ComparaÃ§Ã£o com ExecuÃ§Ãµes Anteriores" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Contar execuÃ§Ãµes anteriores
          previous_count=$(find ./previous-reports -name "*.jtl" 2>/dev/null | wc -l)
          echo "**ExecuÃ§Ãµes Anteriores Analisadas:** $previous_count" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ $previous_count -gt 0 ]; then
            echo "âœ… Dados histÃ³ricos disponÃ­veis para anÃ¡lise de tendÃªncias" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ðŸŽ¯ RecomendaÃ§Ãµes:" >> $GITHUB_STEP_SUMMARY
            echo "- Monitorar tendÃªncias de degradaÃ§Ã£o de performance" >> $GITHUB_STEP_SUMMARY
            echo "- Alertar se tempo de resposta aumentar > 20%" >> $GITHUB_STEP_SUMMARY
            echo "- Investigar picos de uso de CPU/memÃ³ria" >> $GITHUB_STEP_SUMMARY
          else
            echo "âš ï¸ Dados histÃ³ricos insuficientes para anÃ¡lise de tendÃªncias" >> $GITHUB_STEP_SUMMARY
            echo "Execute mais execuÃ§Ãµes para estabelecer baseline" >> $GITHUB_STEP_SUMMARY
          fi

  # =============================================================================
  # Job: Alertas de Performance
  # =============================================================================
  performance-alerts:
    name: ðŸš¨ Alertas de Performance
    runs-on: ubuntu-latest
    needs: [performance-tests, system-monitoring]
    if: always()

    steps:
      - name: ðŸ“Š Verificar thresholds de performance
        run: |
          echo "## ðŸš¨ VerificaÃ§Ã£o de Alertas" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Verificar se hÃ¡ relatÃ³rios de performance
          if [ -f "automation/performance/results/performance_results.jtl" ]; then
            # Extrair mÃ©tricas crÃ­ticas
            total_requests=$(tail -n +2 automation/performance/results/performance_results.jtl | wc -l)
            successful_requests=$(tail -n +2 automation/performance/results/performance_results.jtl | awk -F',' '$8=="true"' | wc -l)
            success_rate=$((successful_requests * 100 / total_requests))
            
            # Calcular tempo mÃ©dio de resposta
            avg_response_time=$(tail -n +2 automation/performance/results/performance_results.jtl | awk -F',' '{sum+=$2; count++} END {print sum/count}')
            
            echo "### ðŸ“Š MÃ©tricas Atuais:" >> $GITHUB_STEP_SUMMARY
            echo "- **Taxa de Sucesso:** $success_rate%" >> $GITHUB_STEP_SUMMARY
            echo "- **Tempo MÃ©dio de Resposta:** ${avg_response_time}ms" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Verificar alertas
            alerts=0
            
            if [ $success_rate -lt 95 ]; then
              echo "ðŸš¨ **ALERTA:** Taxa de sucesso abaixo de 95% ($success_rate%)" >> $GITHUB_STEP_SUMMARY
              alerts=$((alerts + 1))
            fi
            
            if (( $(echo "$avg_response_time > 2000" | bc -l) )); then
              echo "ðŸš¨ **ALERTA:** Tempo de resposta acima de 2s (${avg_response_time}ms)" >> $GITHUB_STEP_SUMMARY
              alerts=$((alerts + 1))
            fi
            
            if [ $alerts -eq 0 ]; then
              echo "âœ… **Status:** Todas as mÃ©tricas dentro dos limites aceitÃ¡veis" >> $GITHUB_STEP_SUMMARY
            else
              echo "âš ï¸ **Total de Alertas:** $alerts" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "âš ï¸ RelatÃ³rios de performance nÃ£o encontrados" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ðŸ“¢ Notificar alertas crÃ­ticos
        uses: 8398a7/action-slack@v3
        if: failure()
        with:
          status: failure
          channel: '#performance-alerts'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
          fields: repo,message,commit,author,action,eventName,ref,workflow
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # =============================================================================
  # Job: RelatÃ³rio Final
  # =============================================================================
  final-report:
    name: ðŸ“‹ RelatÃ³rio Final
    runs-on: ubuntu-latest
    needs: [performance-tests, system-monitoring, trend-analysis, performance-alerts]
    if: always()

    steps:
      - name: ðŸ“Š Gerar relatÃ³rio final
        run: |
          echo "## ðŸ“‹ RelatÃ³rio de Monitoramento de Performance" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Data/Hora:** $(date -u +'%d/%m/%Y %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**ExecuÃ§Ã£o:** ${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Status dos Jobs:" >> $GITHUB_STEP_SUMMARY
          echo "- âš¡ Testes de Performance: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ–¥ï¸ Monitoramento do Sistema: ${{ needs.system-monitoring.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“ˆ AnÃ¡lise de TendÃªncias: ${{ needs.trend-analysis.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸš¨ Alertas de Performance: ${{ needs.performance-alerts.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸŽ¯ PrÃ³ximos Passos:" >> $GITHUB_STEP_SUMMARY
          echo "1. Revisar mÃ©tricas coletadas" >> $GITHUB_STEP_SUMMARY
          echo "2. Investigar alertas se houver" >> $GITHUB_STEP_SUMMARY
          echo "3. Ajustar thresholds se necessÃ¡rio" >> $GITHUB_STEP_SUMMARY
          echo "4. Planejar otimizaÃ§Ãµes baseadas nos dados" >> $GITHUB_STEP_SUMMARY
